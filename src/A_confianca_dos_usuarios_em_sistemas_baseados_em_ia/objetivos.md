# Objetivos

## Objetivo Geral

Investigar os fatores que influenciam a confiança dos usuários em sistemas baseados em Inteligência Artificial, analisando suas percepções, experiências e expectativas em relação à transparência, explicabilidade, responsabilidade e outros princípios éticos aplicados ao design de sistemas.

## Objetivos Específicos

* Mapear as principais definições e dimensões da confiança em sistemas de IA, considerando aspectos técnicos, socioéticos e características dos usuários, conforme identificado em estudos recentes (BACH et al., 2024).
* Analisar como fatores externos, como preocupações éticas, riscos percebidos e exposição midiática, afetam a formação da confiança dos usuários (SARGENT et al., 2024).
* Investigar o impacto da opacidade e da falta de explicabilidade dos sistemas de IA na percepção de confiança dos usuários (BACH et al., 2024; LIAO; SUNDAR, 2022).
* Explorar o papel das estratégias de comunicação e design na construção de sinais de confiabilidade percebida, como proposto no modelo MATCH (LIAO; SUNDAR, 2022).
* Propor diretrizes para o design ético e centrado no humano de sistemas de IA, fundamentadas nos princípios de transparência, responsabilidade, justiça e inclusão destacados pela UNESCO (2021) e por Kieslich, Keller e Starke (2022).